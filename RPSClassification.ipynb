{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wGGXdTEF0XQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import Compose, Normalize, Resize, ToTensor, ToPILImage, RandomRotation, CenterCrop\n",
        "from torch.utils.data import DataLoader, Dataset,random_split\n",
        "from torchsummary import summary\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve\n",
        "\n",
        "from torchvision.models import alexnet\n",
        "from torchvision.models.alexnet import model_urls\n",
        "from torchvision.models.utils import load_state_dict_from_url\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def testModel(model,testImages,normTransform,label):\n",
        "    out = model(normTransform(testImages).to(device))\n",
        "    out=F.softmax(out)\n",
        "    preidctions=np.argmax(out.detach().cpu().numpy(),1)\n",
        "    predictedClasses=np.array(trainSet.classes)[preidctions]\n",
        "    GTClasses=np.array(trainSet.classes)[label]\n",
        "    ################################################## display a batch\n",
        "    plt.figure()\n",
        "    for i in range(6):\n",
        "        pilImge=ToPILImage()(testImages[i])\n",
        "        plt.subplot(2,3,i+1)\n",
        "        plt.imshow(pilImge)\n",
        "        plt.title(predictedClasses[i]+'_'+GTClasses[i])\n",
        "    plt.show(block=True)\n",
        "\n",
        "\n",
        "\n",
        "#transforms\n",
        "normTransform=Normalize(mean=torch.Tensor([0.485, 0.456, 0.406]),std=torch.Tensor([0.229, 0.224, 0.225]))\n",
        "transform=Compose([Resize(256),CenterCrop(224), ToTensor(), normTransform])\n",
        "#Datasets & Loaders\n",
        "trainSet=ImageFolder(root='dataset/rps/',transform=transform)\n",
        "train_loader=DataLoader(trainSet, batch_size=128, shuffle=True)\n",
        "valSet=ImageFolder(root='dataset/rps-test-set/',transform=transform)\n",
        "val_loader=DataLoader(valSet, batch_size=128)\n",
        "\n",
        "\n",
        "transform2=Compose([Resize(256), CenterCrop(224),ToTensor()])\n",
        "testSet=ImageFolder(root='dataset/rps-test-set/',transform=transform2)\n",
        "test_loader=DataLoader(testSet, batch_size=6,shuffle=True)\n",
        "################################################## display a batch\n",
        "testImages,label=next(iter(test_loader))\n",
        "GTClasses=np.array(trainSet.classes)[label]\n",
        "for i in range(6):\n",
        "    pilImge=ToPILImage()(testImages[i])\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(pilImge)\n",
        "    plt.title(GTClasses[i])\n",
        "\n",
        "plt.show(block=True)\n",
        "#####################################################\n",
        "\n",
        "#loading a pretrained model\n",
        "model = alexnet(pretrained=False)\n",
        "url = model_urls['alexnet']\n",
        "state_dict = load_state_dict_from_url(url, model_dir='pretrained', progress=True)\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)\n",
        "summary(model,(3,224,224))\n",
        "\n",
        "#freezing it's all weights\n",
        "for parameter in model.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "model.classifier[6] = nn.Linear(4096, 3)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        print(name)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "num_params = sum(param.numel() for param in model.parameters())\n",
        "num_trainable_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
        "\n",
        "\n",
        "#testing model befre training on some test images\n",
        "testModel(model,testImages,normTransform,label)\n",
        "\n",
        "\n",
        "lr=3e-4\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#tensorboard\n",
        "tboardWriter=SummaryWriter('runs/RPSClassification-CNN')\n",
        "\n",
        "\n",
        "#batch wise training loop\n",
        "epochs = 20\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_accuracy=0\n",
        "for epoch in range(epochs):  #epochs loop\n",
        "\n",
        "    all_Y_train_epoch=np.array([]).reshape(0,1)\n",
        "    all_Yhat_train_epoch=np.array([]).reshape(0,1)\n",
        "    all_train_losses_epoch=np.array([])\n",
        "\n",
        "    for X_train, Y_train in train_loader:        #batch wise  training on train set\n",
        "        model.train()\n",
        "        X_train = X_train.to(device)\n",
        "        Y_train = Y_train.to(device)\n",
        "        logits = model(X_train)\n",
        "\n",
        "        loss = loss_fn(logits, Y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #store metrics for all batches of current epoch\n",
        "        y_hat=F.softmax(logits,dim=-1)\n",
        "        y_hat=y_hat.detach().cpu().numpy()\n",
        "        y_hat=np.argmax(y_hat,axis=1)\n",
        "        y_hat=y_hat.reshape(-1,1)\n",
        "\n",
        "        Y_train=Y_train.detach().cpu().numpy()\n",
        "        Y_train=Y_train.reshape(-1,1)\n",
        "        all_Y_train_epoch=np.vstack((all_Y_train_epoch,Y_train))\n",
        "        all_Yhat_train_epoch=np.vstack((all_Yhat_train_epoch,y_hat))\n",
        "        all_train_losses_epoch=np.append(all_train_losses_epoch,loss.item())\n",
        "\n",
        "\n",
        "\n",
        "    #computing metrics for current epoch\n",
        "    train_losses.append(all_train_losses_epoch.mean()) #mean loss for all batches\n",
        "    acTrain=accuracy_score(all_Y_train_epoch, all_Yhat_train_epoch)\n",
        "    cmTrain=confusion_matrix(all_Y_train_epoch, all_Yhat_train_epoch)\n",
        "    print(cmTrain)\n",
        "\n",
        "    #validation loop also bacth wise\n",
        "    all_Y_val_epoch=np.array([]).reshape(0,1)\n",
        "    all_Yhat_val_epoch=np.array([]).reshape(0,1)\n",
        "    all_val_losses_epoch=np.array([])\n",
        "    for X_val, Y_val in val_loader:  #batch wise validation set predictions only\n",
        "        model.eval()\n",
        "\n",
        "        X_val = X_val.to(device)\n",
        "        Y_val = Y_val.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(X_val)\n",
        "            loss = loss_fn(logits, Y_val)\n",
        "\n",
        "        #store metrics for all batches of current epoch\n",
        "        y_hat_val=F.softmax(logits,dim=-1)\n",
        "        y_hat_val=y_hat_val.detach().cpu().numpy()\n",
        "        y_hat_val=np.argmax(y_hat_val,axis=1)\n",
        "        y_hat_val=y_hat_val.reshape(-1,1)\n",
        "        Y_val=Y_val.detach().cpu().numpy()\n",
        "        Y_val=Y_val.reshape(-1,1)\n",
        "        all_Y_val_epoch=np.vstack((all_Y_val_epoch,Y_val))\n",
        "        all_Yhat_val_epoch=np.vstack((all_Yhat_val_epoch,y_hat_val))\n",
        "        all_val_losses_epoch=np.append(all_val_losses_epoch,loss.item())\n",
        "\n",
        "\n",
        "    #computing metrics for current epoch\n",
        "    val_losses.append(all_val_losses_epoch.mean()) #mean loss for all batches\n",
        "    acVal=accuracy_score(all_Y_val_epoch, all_Yhat_val_epoch)\n",
        "    cmVal=confusion_matrix(all_Y_val_epoch, all_Yhat_val_epoch)\n",
        "\n",
        "    print(f\"epoch= {epoch}, accuracyTrain= {acTrain}, accuracyVal= {acVal}, train_loss= {train_losses[epoch]}, validation_loss= {val_losses[epoch]}\")\n",
        "\n",
        "    #checkpointing training\n",
        "    if(acVal>best_accuracy):\n",
        "        checkpoint = {'epoch': epoch,'model_state_dict': model.state_dict(),\n",
        "                      'optimizer_state_dict': optimizer.state_dict(),'loss': train_losses,\n",
        "                      'val_loss': val_losses}\n",
        "        torch.save(checkpoint,'best.pth')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    tboardWriter.add_scalar(\"Loss/train\", train_losses[epoch], epoch)\n",
        "    tboardWriter.add_scalar(\"Loss/val\", val_losses[epoch], epoch)\n",
        "    tboardWriter.add_scalar(\"accuracy/train\", acTrain, epoch)\n",
        "    tboardWriter.add_scalar(\"accuracy/val\", acVal, epoch)\n",
        "\n",
        "\n",
        "#loading best model\n",
        "checkpoint = torch.load('best.pth')\n",
        "# Restore state for model and optimizer\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "total_epochs = checkpoint['epoch']\n",
        "losses = checkpoint['loss']\n",
        "val_losses = checkpoint['val_loss']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#testing model after training on some test images\n",
        "testModel(model,testImages,normTransform,label)"
      ]
    }
  ]
}